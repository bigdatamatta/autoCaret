caret_name,general_name,description,advantage,disadvantage,Wiki_URL
glm,Generalized Linear Model,Model that find linear relationship between input variables and output variable,Easy to understand,Would not apply well to non linear relationship,https://en.wikipedia.org/wiki/Generalized_linear_model
ensemble,Ensemble,The process of running two or more related but different analytical models and then synthesizing the results into a single score or spread,Improve the accuracy of predictive analytics beyond what a single model can be,Hard to interpret the model. ,https://en.wikipedia.org/wiki/Ensemble_learning
rf,Random forest,An ensemble classifier that consists of many decision trees and outputs the class that is the mode of the classes output by individual trees,"Accurate, efficient with large datasets, handles missing data well ",Observed to overfit for some datasets with noisy classification. Hard to interpret the model. ,https://en.wikipedia.org/wiki/Random_forest
xgbLinear,Extreme Gradient Boosting Linear,Incrementally building an ensemble by training each new model instance to emphasize the training instances that previous models mis-classified,Reduce bias and variance,Not reliable on noisy dataset (real world dataset). may overfit training data. Hard to interpret the model. ,https://en.wikipedia.org/wiki/Boosting_(machine_learning)
xgboost,Extreme Gradient Boosting Trees ,Incrementally building an ensemble by training each new model instance to emphasize the training instances that previous models mis-classified,Reduce bias and variance,Not reliable on noisy dataset (real world dataset). may overfit training data. Hard to interpret the model. ,https://en.wikipedia.org/wiki/Boosting_(machine_learning)
rpart,Recursive partitioning trees,Recursive partitioning creates a decision tree that strives to correctly classify members of the population by splitting it into sub-populations based on several dichotomous independent variables. The process is termed recursive because each sub-population may in turn be split an indefinite number of times until the splitting process terminates after a particular stopping criterion is reached.,Generates clinically more intuitive models that do not require the user to perform calculations. Allows varying prioritizing of misclassifications in order to create a decision rule that has more sensitivity or specificity. May be more accurate. ,Does not work well for continuous variables. May overfit data.,
