<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Greg Ceccarelli" />

<meta name="date" content="2016-12-06" />

<title>Getting Started with autoCaret</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Getting Started with autoCaret</h1>
<h4 class="author"><em>Greg Ceccarelli</em></h4>
<h4 class="date"><em>2016-12-06</em></h4>



<p>This vignette is designed to introduce you to the <code>autoCaret</code> R package. This package is built on top of both the <a href="https://cran.r-project.org/web/packages/caret/">caret</a> and <a href="https://cran.r-project.org/web/packages/caretEnsemble/">caretEnsemble</a> R packages for machine learning and can take as input an R dataframe suitable for binary classification. Currently, <a href="https://en.wikipedia.org/wiki/Binary_classification">binary classification</a>, is the primary purpose of <code>autoCaret</code>.</p>
<p>The main function, <code>automodel</code>, will do the following:</p>
<ol style="list-style-type: decimal">
<li>Validate the input data frame - binarizing the target variable if possible.</li>
<li>Split the dataframe into both a training and test set</li>
<li>Preprocess the input data - center, scale and remove variables with zero variance</li>
<li>Check for class imbalance and attempt to downsample, as default, to help combat poor predictive accuracy</li>
<li>Build a suite of models determined by the <code>methodlist</code> parameter. If NULL, defaults to “glm”, “rpart”, rf&quot; &amp;“xgbLinear”&quot;</li>
<li>Blend the models into an ensemble model using the <code>caretEnsemble</code> package</li>
<li>Use the ensemble to make predictions on the held out test set</li>
<li>Return, to the end user, an <code>autoCaret</code> model object with a variety of useful pieces of metadata about the modeling process</li>
</ol>
<p>The <code>autoCaret</code> model object is fully accessible and can be summarized using the the <code>summary()</code> generic function.</p>
<p>Additionally, predictions can be made using the <code>predict()</code> generic function passing in as parameters an <code>autoCaret</code> object and new data.</p>
<hr />
<div id="installation" class="section level2">
<h2>Installation</h2>
<p>At the time of this writing, this package is not hosted on CRAN, but can be obtained from GitHub. To do so, first make sure you have <a href="https://cran.r-project.org/web/packages/devtools/index.html">devtools</a> installed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;devtools&quot;</span>)</code></pre></div>
<p>Now we can install from GitHub using the following line:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools::<span class="kw">install_github</span>(<span class="st">&quot;gregce/autoCaret&quot;</span>)</code></pre></div>
<p>Once the <code>autoCaret</code> package is installed, you may access its functionality as you would any other package by calling:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;autoCaret&quot;</span>)</code></pre></div>
<p>If all went well, check out the vignette(“autoCaret”) which will pull up this vignette!</p>
</div>
<div id="basic-usage" class="section level2">
<h2>Basic Usage</h2>
<p>We begin by loading the <code>mlbench</code> pakacage and some example data, Sonar, which is commonly used to demostrate machine learning functionality. In this example, we will attempt to distinguish Mines (M) from Rocks (R) using binary classification with an initial dataset of where N=208 and P=60.</p>
<p>As a general rule, when using <code>autoCaret::autoModel</code> defaults, datasets less than 100mb should yield optimal performance. and in order to avoid extremely long run times and/or high memory requirements.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mlbench)
<span class="kw">library</span>(autoCaret)

<span class="co"># Load the data into Memory from the mlbench package</span>
<span class="kw">data</span>(<span class="st">&quot;Sonar&quot;</span>)

<span class="co"># Take a brief peak at the Sonar dataframe</span>
dplyr::<span class="kw">glimpse</span>(Sonar)</code></pre></div>
<pre><code>## Observations: 208
## Variables: 61
## $ V1    &lt;dbl&gt; 0.0200, 0.0453, 0.0262, 0.0100, 0.0762, 0.0286, 0.0317, ...
## $ V2    &lt;dbl&gt; 0.0371, 0.0523, 0.0582, 0.0171, 0.0666, 0.0453, 0.0956, ...
## $ V3    &lt;dbl&gt; 0.0428, 0.0843, 0.1099, 0.0623, 0.0481, 0.0277, 0.1321, ...
## $ V4    &lt;dbl&gt; 0.0207, 0.0689, 0.1083, 0.0205, 0.0394, 0.0174, 0.1408, ...
## $ V5    &lt;dbl&gt; 0.0954, 0.1183, 0.0974, 0.0205, 0.0590, 0.0384, 0.1674, ...
## $ V6    &lt;dbl&gt; 0.0986, 0.2583, 0.2280, 0.0368, 0.0649, 0.0990, 0.1710, ...
## $ V7    &lt;dbl&gt; 0.1539, 0.2156, 0.2431, 0.1098, 0.1209, 0.1201, 0.0731, ...
## $ V8    &lt;dbl&gt; 0.1601, 0.3481, 0.3771, 0.1276, 0.2467, 0.1833, 0.1401, ...
## $ V9    &lt;dbl&gt; 0.3109, 0.3337, 0.5598, 0.0598, 0.3564, 0.2105, 0.2083, ...
## $ V10   &lt;dbl&gt; 0.2111, 0.2872, 0.6194, 0.1264, 0.4459, 0.3039, 0.3513, ...
## $ V11   &lt;dbl&gt; 0.1609, 0.4918, 0.6333, 0.0881, 0.4152, 0.2988, 0.1786, ...
## $ V12   &lt;dbl&gt; 0.1582, 0.6552, 0.7060, 0.1992, 0.3952, 0.4250, 0.0658, ...
## $ V13   &lt;dbl&gt; 0.2238, 0.6919, 0.5544, 0.0184, 0.4256, 0.6343, 0.0513, ...
## $ V14   &lt;dbl&gt; 0.0645, 0.7797, 0.5320, 0.2261, 0.4135, 0.8198, 0.3752, ...
## $ V15   &lt;dbl&gt; 0.0660, 0.7464, 0.6479, 0.1729, 0.4528, 1.0000, 0.5419, ...
## $ V16   &lt;dbl&gt; 0.2273, 0.9444, 0.6931, 0.2131, 0.5326, 0.9988, 0.5440, ...
## $ V17   &lt;dbl&gt; 0.3100, 1.0000, 0.6759, 0.0693, 0.7306, 0.9508, 0.5150, ...
## $ V18   &lt;dbl&gt; 0.2999, 0.8874, 0.7551, 0.2281, 0.6193, 0.9025, 0.4262, ...
## $ V19   &lt;dbl&gt; 0.5078, 0.8024, 0.8929, 0.4060, 0.2032, 0.7234, 0.2024, ...
## $ V20   &lt;dbl&gt; 0.4797, 0.7818, 0.8619, 0.3973, 0.4636, 0.5122, 0.4233, ...
## $ V21   &lt;dbl&gt; 0.5783, 0.5212, 0.7974, 0.2741, 0.4148, 0.2074, 0.7723, ...
## $ V22   &lt;dbl&gt; 0.5071, 0.4052, 0.6737, 0.3690, 0.4292, 0.3985, 0.9735, ...
## $ V23   &lt;dbl&gt; 0.4328, 0.3957, 0.4293, 0.5556, 0.5730, 0.5890, 0.9390, ...
## $ V24   &lt;dbl&gt; 0.5550, 0.3914, 0.3648, 0.4846, 0.5399, 0.2872, 0.5559, ...
## $ V25   &lt;dbl&gt; 0.6711, 0.3250, 0.5331, 0.3140, 0.3161, 0.2043, 0.5268, ...
## $ V26   &lt;dbl&gt; 0.6415, 0.3200, 0.2413, 0.5334, 0.2285, 0.5782, 0.6826, ...
## $ V27   &lt;dbl&gt; 0.7104, 0.3271, 0.5070, 0.5256, 0.6995, 0.5389, 0.5713, ...
## $ V28   &lt;dbl&gt; 0.8080, 0.2767, 0.8533, 0.2520, 1.0000, 0.3750, 0.5429, ...
## $ V29   &lt;dbl&gt; 0.6791, 0.4423, 0.6036, 0.2090, 0.7262, 0.3411, 0.2177, ...
## $ V30   &lt;dbl&gt; 0.3857, 0.2028, 0.8514, 0.3559, 0.4724, 0.5067, 0.2149, ...
## $ V31   &lt;dbl&gt; 0.1307, 0.3788, 0.8512, 0.6260, 0.5103, 0.5580, 0.5811, ...
## $ V32   &lt;dbl&gt; 0.2604, 0.2947, 0.5045, 0.7340, 0.5459, 0.4778, 0.6323, ...
## $ V33   &lt;dbl&gt; 0.5121, 0.1984, 0.1862, 0.6120, 0.2881, 0.3299, 0.2965, ...
## $ V34   &lt;dbl&gt; 0.7547, 0.2341, 0.2709, 0.3497, 0.0981, 0.2198, 0.1873, ...
## $ V35   &lt;dbl&gt; 0.8537, 0.1306, 0.4232, 0.3953, 0.1951, 0.1407, 0.2969, ...
## $ V36   &lt;dbl&gt; 0.8507, 0.4182, 0.3043, 0.3012, 0.4181, 0.2856, 0.5163, ...
## $ V37   &lt;dbl&gt; 0.6692, 0.3835, 0.6116, 0.5408, 0.4604, 0.3807, 0.6153, ...
## $ V38   &lt;dbl&gt; 0.6097, 0.1057, 0.6756, 0.8814, 0.3217, 0.4158, 0.4283, ...
## $ V39   &lt;dbl&gt; 0.4943, 0.1840, 0.5375, 0.9857, 0.2828, 0.4054, 0.5479, ...
## $ V40   &lt;dbl&gt; 0.2744, 0.1970, 0.4719, 0.9167, 0.2430, 0.3296, 0.6133, ...
## $ V41   &lt;dbl&gt; 0.0510, 0.1674, 0.4647, 0.6121, 0.1979, 0.2707, 0.5017, ...
## $ V42   &lt;dbl&gt; 0.2834, 0.0583, 0.2587, 0.5006, 0.2444, 0.2650, 0.2377, ...
## $ V43   &lt;dbl&gt; 0.2825, 0.1401, 0.2129, 0.3210, 0.1847, 0.0723, 0.1957, ...
## $ V44   &lt;dbl&gt; 0.4256, 0.1628, 0.2222, 0.3202, 0.0841, 0.1238, 0.1749, ...
## $ V45   &lt;dbl&gt; 0.2641, 0.0621, 0.2111, 0.4295, 0.0692, 0.1192, 0.1304, ...
## $ V46   &lt;dbl&gt; 0.1386, 0.0203, 0.0176, 0.3654, 0.0528, 0.1089, 0.0597, ...
## $ V47   &lt;dbl&gt; 0.1051, 0.0530, 0.1348, 0.2655, 0.0357, 0.0623, 0.1124, ...
## $ V48   &lt;dbl&gt; 0.1343, 0.0742, 0.0744, 0.1576, 0.0085, 0.0494, 0.1047, ...
## $ V49   &lt;dbl&gt; 0.0383, 0.0409, 0.0130, 0.0681, 0.0230, 0.0264, 0.0507, ...
## $ V50   &lt;dbl&gt; 0.0324, 0.0061, 0.0106, 0.0294, 0.0046, 0.0081, 0.0159, ...
## $ V51   &lt;dbl&gt; 0.0232, 0.0125, 0.0033, 0.0241, 0.0156, 0.0104, 0.0195, ...
## $ V52   &lt;dbl&gt; 0.0027, 0.0084, 0.0232, 0.0121, 0.0031, 0.0045, 0.0201, ...
## $ V53   &lt;dbl&gt; 0.0065, 0.0089, 0.0166, 0.0036, 0.0054, 0.0014, 0.0248, ...
## $ V54   &lt;dbl&gt; 0.0159, 0.0048, 0.0095, 0.0150, 0.0105, 0.0038, 0.0131, ...
## $ V55   &lt;dbl&gt; 0.0072, 0.0094, 0.0180, 0.0085, 0.0110, 0.0013, 0.0070, ...
## $ V56   &lt;dbl&gt; 0.0167, 0.0191, 0.0244, 0.0073, 0.0015, 0.0089, 0.0138, ...
## $ V57   &lt;dbl&gt; 0.0180, 0.0140, 0.0316, 0.0050, 0.0072, 0.0057, 0.0092, ...
## $ V58   &lt;dbl&gt; 0.0084, 0.0049, 0.0164, 0.0044, 0.0048, 0.0027, 0.0143, ...
## $ V59   &lt;dbl&gt; 0.0090, 0.0052, 0.0095, 0.0040, 0.0107, 0.0051, 0.0036, ...
## $ V60   &lt;dbl&gt; 0.0032, 0.0044, 0.0078, 0.0117, 0.0094, 0.0062, 0.0103, ...
## $ Class &lt;fctr&gt; R, R, R, R, R, R, R, R, R, R, R, R, R, R, R, R, R, R, R...</code></pre>
<p>Having both the data loaded and having inspected it, we can now make use of the <code>autoCaret::autoModel()</code> function As stated above, we intend to try and distinguish Rocks (R) from Mines (R), so we will attempt to predict the <code>Class</code> variable in the Sonar dataframe.</p>
<p>Using it’s defaults, <code>autoModel</code> has 2 arguments we need to specify: <code>df</code> and <code>y</code>.</p>
<p><code>df</code> is the Dataframe that we’d like to use build a binary classification model, while <code>y</code> is our classification target or response variable. We can use a non-exported package function, <code>autoCaret:::checkBinaryTrait</code> to determine if our <code>y</code> variable is indeed binary. The <code>autoModel</code> functionality will perform this for us as well.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Manually check that our intended y paramter is indeed binary</span>
autoCaret:::<span class="kw">checkBinaryTrait</span>(Sonar$Class)</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate an autoCaret object using the autoModel function</span>
mod &lt;-<span class="st"> </span>autoCaret::<span class="kw">autoModel</span>(<span class="dt">df =</span> Sonar, <span class="dt">y =</span> Class, <span class="dt">progressBar =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>In the example above, the returned object, <code>mod</code>, is an <code>autoCaret</code> object containing 16 objects. To confirm, we can run the below two commmands:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Check class of autoCaret object</span>
<span class="kw">class</span>(mod)</code></pre></div>
<pre><code>## [1] &quot;autoCaret&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># High level </span>
<span class="kw">nrow</span>(<span class="kw">summary.default</span>(mod))</code></pre></div>
<pre><code>## [1] 19</code></pre>
<p>Running the summary function on our model output displays a wealth of information about the contents of the object as well as the procedural steps taken during modeling. In our example, we observe:</p>
<ul>
<li>that our initial dataset of 208 observation was split into a training and test set containing 167 and 41 observations</li>
<li>Modeling took .64 minutes and entailed resampling our dataset 10 times</li>
<li>We used the four default models to create an ensemble.</li>
<li>Using the ensemble model that was generated to predict on the test set yield predictions with 92% accuracy.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use the summary generic to store a summary of autoCaret object</span>
overview &lt;-<span class="st"> </span><span class="kw">summary</span>(mod)</code></pre></div>
<pre><code>## The input dataset had: 208 observations and 60 predictors 
## ---------------------
## Prior to model training, the input dataset was split into a training &amp; test set 
## The training set has:  167  observations 
## The test set has:      41  observations 
## ---------------------
## Overall modeling took: 0.64 minutes 
## During that time the training data was boostrap resampled 10 times 
## 
## The following classification models were used to create an ensemble: 
## - glm
## - rpart
## - rf
## - xgbLinear
## To learn more about ensemble learing in the context of machine learning, please visit: https://en.wikipedia.org/wiki/Ensemble_learning 
## 
## In the ensemble, the top 5 variables in order from highest to lowest level of relative importance, were: 
## -  V11
## -  V12
## -  V9
## -  V10
## -  V36
## ---------------------
## When the ensemble model was used to predict on the held out test set of 41 observations it performed as follows: 
## 
## Overall Accuracy: 92.68
## 
## A confusion matrix demonstrating accuracy is as follows: 
##           Reference
## Prediction  R  M
##          R 18  2
##          M  1 20
## 
## Precision: 90
## Recall: 94.74
## ---------------------
## To learn more about Precision &amp; Recall in the context of information retriveal, please visit: https://en.wikipedia.org/wiki/Precision_and_recall</code></pre>
<p>We can also access each of object variables included in the above displayed summary output via the object itself.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Print the overview to the console</span>
overview</code></pre></div>
<pre><code>## $input_row_count
## [1] 208
## 
## $input_col_count
## [1] 61
## 
## $train_row_count
## [1] 167
## 
## $test_row_count
## [1] 41
## 
## $modeling_time
## [1] 0.64
## 
## $number_resamples
## [1] 10
## 
## $method_list
## [1] &quot;glm&quot;       &quot;rpart&quot;     &quot;rf&quot;        &quot;xgbLinear&quot;
## 
## $confusionMatrix
##           Reference
## Prediction  R  M
##          R 18  2
##          M  1 20
## 
## $accuracy
## [1] 92.68
## 
## $sensitivity
## [1] 94.74
## 
## $specificity
## [1] 90.91
## 
## $precision
## [1] 90
## 
## $recall
## [1] 94.74
## 
## $best_model_results
##   model_name       ROC      Sens      Spec      ROCSD     SensSD
## 1   ensemble 0.9337900 0.8095031 0.8953181 0.01498452 0.01089121
## 2         rf 0.9052501 0.6901687 0.8829980 0.03551813 0.10603065
## 3  xgbLinear 0.8702916 0.7168320 0.8185311 0.04529174 0.10874655
## 4      rpart 0.7019527 0.6562942 0.7122567 0.08602055 0.15284623
## 5        glm 0.6451431 0.5910052 0.6543618 0.08914517 0.08671003
##       SpecSD
## 1 0.04371527
## 2 0.06784535
## 3 0.08614794
## 4 0.07226794
## 5 0.10772096
## 
## attr(,&quot;class&quot;)
## [1] &quot;summary.autoCaret&quot;</code></pre>
</div>
<div id="predicting-new-data" class="section level2">
<h2>Predicting new data</h2>
<p>So now that we have a sense of how successful our auto modeling approach was, we’d likely want to use the model, <code>mod</code>, we built previously to make predictions on new data we receive.</p>
<p>Because this is an illustrative example, we’lll take a shortcut by just resampling the same data that we used to train on. The main point here is that you can simply pass your <code>autoCaret</code> model object, <code>mod</code>, into the <code>predict()</code> function along with new observations to generate predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">new &lt;-<span class="st"> </span>Sonar[<span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(Sonar), <span class="dv">50</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>),]

<span class="co">#Make predicitons </span>
preds &lt;-<span class="st"> </span><span class="kw">predict</span>(mod, new)

<span class="co">#Print Predictions </span>
preds</code></pre></div>
<pre><code>##  [1] M R M R R R R M R M R M M R M R R M M R M M M M R M M M R R M R R M M
## [36] R M M M R R M M M R M M M M R
## Levels: R M</code></pre>
<p>How well did we do? Well a confusion matrix from the <code>caret</code> package can tell us!</p>
<ul>
<li>We only mispredicted one example, for overall accuracy of .98</li>
<li><strong>Note:</strong> we wouldn’t expect this level of accuracy using real data given we resampled from our original training set.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## How well did we do?
caret::<span class="kw">confusionMatrix</span>(<span class="dt">data =</span> preds, <span class="dt">reference =</span> new$Class)</code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  M  R
##          M 29  0
##          R  1 20
##                                           
##                Accuracy : 0.98            
##                  95% CI : (0.8935, 0.9995)
##     No Information Rate : 0.6             
##     P-Value [Acc &gt; NIR] : 2.775e-10       
##                                           
##                   Kappa : 0.9587          
##  Mcnemar's Test P-Value : 1               
##                                           
##             Sensitivity : 0.9667          
##             Specificity : 1.0000          
##          Pos Pred Value : 1.0000          
##          Neg Pred Value : 0.9524          
##              Prevalence : 0.6000          
##          Detection Rate : 0.5800          
##    Detection Prevalence : 0.5800          
##       Balanced Accuracy : 0.9833          
##                                           
##        'Positive' Class : M               
## </code></pre>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
